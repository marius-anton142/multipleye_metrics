# -*- coding: utf-8 -*-
"""plot_charts_all.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sblw9S8MzE-D5qaIOlcDy2RYghg9ttdy
"""

import pickle
import pandas as pd
import plotly.graph_objects as go
import os, re, sys, subprocess

#use generate_language_data.ipynb to create pickle file, then load it here to plot charts

with open("pronouns_by_lang.pkl", "rb") as f:
    pronouns_by_lang = pickle.load(f)

lang_order = list(pronouns_by_lang.keys())
all_docs = sorted(set().union(*[d["doc"]["stimulus_name"] for d in pronouns_by_lang.values()]))

COLOR_PALETTE = [
    "#ef4444", "#f59e0b", "#10b981", "#3b82f6", "#8b5cf6",
    "#ec4899", "#22c55e", "#06b6d4", "#eab308", "#a855f7",
    "#f97316", "#84cc16", "#14b8a6", "#0ea5e9", "#f43f5e",
]

lang_order = list(pronouns_by_lang.keys())
LANG_COLORS = {lang: COLOR_PALETTE[i % len(COLOR_PALETTE)] for i, lang in enumerate(lang_order)}
DEFAULT_COLOR = "#111827"

def color_for(lang):
    return LANG_COLORS.get(lang, DEFAULT_COLOR)

base_df = pronouns_by_lang[lang_order[0]]["sentence"]
SENT_COL = "sentence" if "sentence" in base_df.columns else "sent_idx"

def make_page_stats(df):
    if "page" not in df.columns:
        return pd.DataFrame(columns=["stimulus_name","page","mean","sem"])
    return (df.assign(page=pd.to_numeric(df["page"], errors="coerce"))
              .dropna(subset=["page"])
              .groupby(["stimulus_name","page"], as_index=False)
              .agg(mean=("pronouns","mean"), sem=("pronouns","sem")))

def make_sent_stats(df):
    df = df.copy()
    df["page"] = pd.to_numeric(df.get("page", pd.NA), errors="coerce")
    df[SENT_COL] = pd.to_numeric(df[SENT_COL], errors="coerce")
    df = df.dropna(subset=["stimulus_name",SENT_COL]).sort_values(["stimulus_name","page",SENT_COL])
    df["sent_global"] = df.groupby("stimulus_name").cumcount() + 1
    return df.groupby(["stimulus_name","sent_global"], as_index=False).agg(mean=("pronouns","mean"))

page_stats = {lang: make_page_stats(pronouns_by_lang[lang]["sentence"]) for lang in lang_order}
sent_stats = {lang: make_sent_stats(pronouns_by_lang[lang]["sentence"]) for lang in lang_order}
doc_stats = {lang: (pronouns_by_lang[lang]["sentence"]
                     .groupby("stimulus_name", as_index=False)
                     .agg(mean=("pronouns","mean"), sem=("pronouns","sem")))
             for lang in lang_order}

all_docs = sorted(set().union(
    *[d["stimulus_name"] for d in page_stats.values()],
    *[d["stimulus_name"] for d in sent_stats.values()],
    *[d["stimulus_name"] for d in doc_stats.values()],
))

doc_pages_index = {doc: sorted(set(pd.concat([df.loc[df["stimulus_name"]==doc,"page"] for df in page_stats.values()], ignore_index=True).dropna().astype(int))) for doc in all_docs}
doc_max_sents = {doc: int(max([df.loc[df["stimulus_name"]==doc,"sent_global"].max() for df in sent_stats.values()] or [0])) for doc in all_docs}

rows = []
for lang in lang_order:
    df = pronouns_by_lang[lang]["sentence"]
    rows.append({
        "lang": lang,
        "mean": df["pronouns"].mean(),
        "sem": df["pronouns"].sem()
    })
lang_df = pd.DataFrame(rows)

subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "kaleido==0.2.1"])

ROOT_HTML = "html"
ROOT_PDF  = "pdf"
SUBS = {"doc": "doc", "page": "page", "sentence": "sentence"}

for root in (ROOT_HTML, ROOT_PDF):
    os.makedirs(root, exist_ok=True)
    for sub in SUBS.values():
        os.makedirs(os.path.join(root, sub), exist_ok=True)

def _slug(s):
    s = re.sub(r"\s+", "_", str(s).strip())
    s = re.sub(r"[^0-9A-Za-z_\-]+", "_", s)
    s = re.sub(r"_+", "_", s).strip("_")
    return s.lower() or "untitled"

def _ensure_kaleido():
    try:
        import kaleido
    except Exception:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "kaleido"])

def save_both(fig, html_path, pdf_path):
    fig.write_html(html_path, include_plotlyjs="cdn", full_html=True)
    fig.write_image(pdf_path, engine="kaleido")

# build + save fig_lang
fig_lang = go.Figure()
for lang in lang_order:
    row = lang_df[lang_df["lang"] == lang].iloc[0]
    fig_lang.add_trace(go.Bar(
        x=[lang],
        y=[row["mean"]],
        error_y=dict(type="data", array=[row["sem"]]),
        name=lang,
        marker_color=color_for(lang),
    ))
fig_lang.update_layout(
    barmode="group",
    yaxis_title="Avg pronouns per sentence",
    title="Avg pronouns per sentence by language",
    template="plotly_white",
)
fig_lang.update_xaxes(categoryorder="array", categoryarray=lang_order)
save_both(
    fig_lang,
    os.path.join("html", "doc", "pronouns_all_languages.html"),
    os.path.join("pdf",  "doc", "pronouns_all_languages.pdf"),
)

# doc plots
per_text_figs = {}
for doc_name in all_docs:
    fig = go.Figure()
    for lang in lang_order:
        df = doc_stats[lang]
        row = df[df["stimulus_name"] == doc_name]
        if row.empty:
            continue
        mean_val = float(row["mean"].iloc[0])
        sem_raw = row["sem"].iloc[0]
        sem_val = float(0.0 if pd.isna(sem_raw) else sem_raw)
        fig.add_trace(go.Bar(
            x=[lang], y=[mean_val],
            error_y=dict(type="data", array=[sem_val]),
            name=lang, marker_color=color_for(lang),
            hovertemplate="<b>%{x}</b><br>Avg pronouns/sent: %{y:.3f}<br>SEM: %{customdata:.3f}<extra></extra>",
            customdata=[sem_val],
        ))
    fig.update_layout(
        barmode="group",
        yaxis_title="Avg pronouns per sentence",
        title=f"Pronouns per sentence by language — {doc_name}",
        template="plotly_white",
        showlegend=True,
        margin=dict(l=60, r=20, t=80, b=80),
    )
    fig.update_xaxes(categoryorder="array", categoryarray=lang_order, tickangle=0)
    per_text_figs[doc_name] = fig
    slug = _slug(doc_name)
    save_both(
        fig,
        os.path.join("html", "doc", f"pronouns_{slug}.html"),
        os.path.join("pdf",  "doc", f"pronouns_{slug}.pdf"),
    )

# page plots
per_doc_pages_figs = {}
for doc_name in all_docs:
    pages = doc_pages_index.get(doc_name, [])
    if not pages:
        continue
    x_labels = [f"p{p}" for p in pages]
    fig = go.Figure()
    for lang in lang_order:
        if lang not in page_stats:
            continue
        sub = page_stats[lang].pipe(lambda d: d[d["stimulus_name"] == doc_name]).set_index("page")
        ys = [float(sub.at[p, "mean"]) if p in sub.index else None for p in pages]
        es = [float(sub.at[p, "sem"]) if p in sub.index and pd.notna(sub.at[p, "sem"]) else 0.0 for p in pages]
        fig.add_trace(go.Bar(x=x_labels, y=ys, error_y=dict(type="data", array=es), name=lang, marker_color=color_for(lang)))
    fig.update_layout(barmode="group", yaxis_title="Avg pronouns per sentence", title=f"Avg pronouns per sentence by page — {doc_name}", template="plotly_white", showlegend=True, margin=dict(l=60, r=20, t=80, b=80))
    fig.update_xaxes(tickangle=0)
    per_doc_pages_figs[doc_name] = fig
    slug = _slug(doc_name)
    save_both(
        fig,
        os.path.join("html", "page", f"pronouns_page_{slug}.html"),
        os.path.join("pdf",  "page", f"pronouns_page_{slug}.pdf"),
    )

# sentence plots
per_doc_sentence_figs = {}
for doc_name in all_docs:
    N = doc_max_sents.get(doc_name, 0)
    if N == 0:
        continue
    s_range = list(range(1, N + 1))
    x_labels = [f"s{i}" for i in s_range]
    fig = go.Figure()
    for lang in lang_order:
        df = sent_stats[lang]
        sub = df[df["stimulus_name"] == doc_name].set_index("sent_global")
        ys = [float(sub.at[i, "mean"]) if i in sub.index else None for i in s_range]
        fig.add_trace(go.Bar(x=x_labels, y=ys, name=lang, marker_color=color_for(lang)))
    fig.update_layout(barmode="group", yaxis_title="Pronouns per sentence", title=f"Pronouns per sentence by sentence — {doc_name}", template="plotly_white", showlegend=True, margin=dict(l=60, r=20, t=80, b=80))
    fig.update_xaxes(tickangle=0)
    per_doc_sentence_figs[doc_name] = fig
    slug = _slug(doc_name)
    save_both(
        fig,
        os.path.join("html", "sentence", f"pronouns_sent_{slug}.html"),
        os.path.join("pdf",  "sentence", f"pronouns_sent_{slug}.pdf"),
    )